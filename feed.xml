<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://bekaykang.github.io</id><title>Bekay</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2023-03-07T20:29:04+09:00</updated> <author> <name>Bekay</name> <uri>https://bekaykang.github.io</uri> </author><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="https://bekaykang.github.io" rel="alternate" type="text/html" /> <generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator> <rights> © 2023 Bekay </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>Install Python3.11 in WSL</title><link href="https://bekaykang.github.io/posts/python311_install_wsl/" rel="alternate" type="text/html" title="Install Python3.11 in WSL" /><published>2022-12-13T11:25:00+09:00</published> <updated>2022-12-13T11:25:00+09:00</updated> <id>https://bekaykang.github.io/posts/python311_install_wsl/</id> <content src="https://bekaykang.github.io/posts/python311_install_wsl/" /> <author> <name>Bekay</name> </author> <category term="Issue Fix" /> <summary> Python 3.11 Python3.11 release되면서 많은 관심을 받고있다. 가장 큰 이유는 속도 측면에서 큰 개선이 있다. The Faster CPython Project is already yielding some exciting results. Python 3.11 is up to 10-60% faster than Python 3.10. On average, we measured a 1.22x speedup on the standard benchmark suite. See Faster CPython for details. Install Python 3.11 in WSL Python3.11을 사용하기 위해서 WSL에 설치하는 방법은 아래와 같다. WSL Terminal ... </summary> </entry> <entry><title>Force Directed Method</title><link href="https://bekaykang.github.io/posts/FDM/" rel="alternate" type="text/html" title="Force Directed Method" /><published>2022-11-02T21:25:00+09:00</published> <updated>2022-11-02T23:19:37+09:00</updated> <id>https://bekaykang.github.io/posts/FDM/</id> <content src="https://bekaykang.github.io/posts/FDM/" /> <author> <name>Bekay</name> </author> <category term="Optimization" /> <summary> Force Directed Method에 관한 게시물은 Universität Trier의 Philipp Kindermann 교수 강의를 바탕으로 작성하였습니다. Visualization of Graph 데이터는 다양한 형태 및 특성을 가지고 있습니다. 특정 데이터셋은 Graph로 표현하는 것이 그 특성을 표현하는데 있어서 유리합니다. 예를 들어 나의 인간 관계를 데이터로 표현해야한다면 어떻게 표현하는 것이 가장 좋을까요? Graph 형태로 나의 인간 관계를 표현 하는것이 가장 직관적인 방법일 수 있습니다. 어떻게 Graph를 가장 직관적으로 잘 표현할 수 있을까요? 아래 그림에서 알 수 있듯이 같은 데이터지만 왼쪽보다는 오른쪽이 훨씬 더 직관적입니다. 이렇듯 Graph의 Node와 Edge를 직... </summary> </entry> <entry><title>E169</title><link href="https://bekaykang.github.io/posts/E169/" rel="alternate" type="text/html" title="E169" /><published>2022-06-20T21:25:00+09:00</published> <updated>2022-06-20T22:59:17+09:00</updated> <id>https://bekaykang.github.io/posts/E169/</id> <content src="https://bekaykang.github.io/posts/E169/" /> <author> <name>Bekay</name> </author> <category term="LeetCode" /> <category term="Data Structure" /> <summary> 169. Majority Element Solution class Solution: def majorityElement(self, nums): num_list = sorted(set(nums)) for selec_num in num_list: if nums.count(selec_num) &amp;gt; len(nums)/2: return selec_num solution = Solution() Example nums = [2,2,1,1,1,2,2] ans = solution.majorityElement(nums) print(ans) 2 </summary> </entry> <entry><title>KL Divergence</title><link href="https://bekaykang.github.io/posts/KL_divergence/" rel="alternate" type="text/html" title="KL Divergence" /><published>2022-03-25T21:25:00+09:00</published> <updated>2022-03-26T18:05:56+09:00</updated> <id>https://bekaykang.github.io/posts/KL_divergence/</id> <content src="https://bekaykang.github.io/posts/KL_divergence/" /> <author> <name>Bekay</name> </author> <category term="Optimization" /> <summary> KL Divergence는 무엇인가? Kullback-Leibler divergence(KL Divergence)는 하나의 확률분포로부터 다른 하나의 확률분포가 얼마나 다른지를 정량화한다. Bayesian theory에서 true distribution $P(X)$가 있을 때, 우리는 $P(X)$를 approximate distribution인 $Q(X)$로 추정하고자 한다. 이런 경우, 우리는 KL Divergence를 이용하여 approximate distribution $Q(X)$와 true distribution인 $P(X)$의 차이를 정량화할 수 있다. 수학적으로 두 확률 분포함수 $P$, $Q$가 sample space $X$에 있을 때 KL Divergence는 아래와 같다. \[... </summary> </entry> <entry><title>Pytorch GPU Out of memory Issue</title><link href="https://bekaykang.github.io/posts/OutofMemory/" rel="alternate" type="text/html" title="Pytorch GPU Out of memory Issue" /><published>2021-08-12T21:25:00+09:00</published> <updated>2021-08-13T20:04:31+09:00</updated> <id>https://bekaykang.github.io/posts/OutofMemory/</id> <content src="https://bekaykang.github.io/posts/OutofMemory/" /> <author> <name>Bekay</name> </author> <category term="Issue Fix" /> <summary> GPU Out of Memory Issue Pytorch를 이용하여 모델을 개발하면 아마 한번쯤은 “GPU Out of Memory”를 마주친다. GPU에 대한 이해가 깊다면, 금방 해결할 수 있지만 그렇지 않으면 당황하기 딱 좋은 Error다. 나의 경험은 강화학습을 학습을 할 때, Policy Gradient 기반 Learner를 학습할 때 학습이 진행되면서 GPU Memory도 지속적으로 커지는 현상을 만났다. 다양한 해결방법이 나와있지만, 나의 경우에 해결법은 torch.cuda.empty_cache() 이다! </summary> </entry> </feed>
